{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gestire dati mancanti.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "RG_wqZg2F9K0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Gestire dati mancanti\n",
        "L'operare su dataset in cui alcuni valori sono mancanti è un problema tipico del data preprocessing.\n",
        "Vediamo i metodi da applicare in questo caso, cominciamo importando le librerie che utilizzeremo."
      ]
    },
    {
      "metadata": {
        "id": "QKONCDE3F9K2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LgzaiWcbF9K5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Creiamo il nostro dataset con valori mancanti\n",
        "Per i nostri esempi utilizzeremo l'Iris Dataset, questo famoso dataset non presenta alcun valore mancante, quindi creiamone qualcuno noi.<br>\n",
        "Carichiamo il dataset in un DataFrame."
      ]
    },
    {
      "metadata": {
        "id": "kUQ1mHw_F9K6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "6da2ded5-dca8-4a33-a5e1-9086f4bbc105"
      },
      "cell_type": "code",
      "source": [
        "iris = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\", \n",
        "                   names=[\"sepal_length\",\"sepal_width\",\"petal_length\",\"petal_width\",\"class\"])\n",
        "iris.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal_length  sepal_width  petal_length  petal_width        class\n",
              "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
              "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
              "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
              "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
              "4           5.0          3.6           1.4          0.2  Iris-setosa"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "3gzjZpyRF9K-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        },
        "outputId": "564827ef-f702-4725-9107-27af7fb51ea0"
      },
      "cell_type": "code",
      "source": [
        "iris_nan = iris.copy()\n",
        "max_val = iris.shape[0]\n",
        "\n",
        "samples = np.random.randint(max_val, size=(10)) #Creiamo un vettore di 10 numeri casuali tra 0 e il numero di osservazioni\n",
        "iris_nan.loc[samples,'petal_length']=None #Sostituiamo il valore di \"petal_length\" per ognuna delle 10 osservazioni con un valore non valido\n",
        "\n",
        "nan_count = iris_nan['petal_length'].isnull().sum() #contiamo il numero di valori non validi all'interno della colonna \"petal_legnth\"\n",
        "print(\"Il dataset ha \"+str(nan_count)+\" valori mancanti\")\n",
        "iris_nan.to_csv(\"data/iris_with_nan.csv\") # salviamo il dataset così creato all'interno di un file CSV"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Il dataset ha 10 valori mancanti\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-c20aa7a652a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mnan_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miris_nan\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'petal_length'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#contiamo il numero di valori non validi all'interno della colonna \"petal_legnth\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Il dataset ha \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnan_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\" valori mancanti\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0miris_nan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/iris_with_nan.csv\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# salviamo il dataset così creato all'interno di un file CSV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[1;32m   1522\u001b[0m                                      \u001b[0mdoublequote\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1523\u001b[0m                                      escapechar=escapechar, decimal=decimal)\n\u001b[0;32m-> 1524\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1635\u001b[0m             f, handles = _get_handle(self.path_or_buf, self.mode,\n\u001b[1;32m   1636\u001b[0m                                      \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1637\u001b[0;31m                                      compression=self.compression)\n\u001b[0m\u001b[1;32m   1638\u001b[0m             \u001b[0mclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m             \u001b[0;31m# Python 3 and encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;31m# Python 3 and no explicit encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/iris_with_nan.csv'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "9UyrczOOF9LB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Utilizziamo il DataFrame per caricare il dataset anche in un array numpy"
      ]
    },
    {
      "metadata": {
        "id": "YLhJVF8ZF9LC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Y = iris_nan[\"class\"].values\n",
        "X = iris_nan.drop(\"class\",axis=1).values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2YUfsP_WF9LE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## - Metodo 1: Rimuovere proprietà o esempi con valori mancanti"
      ]
    },
    {
      "metadata": {
        "id": "NF40GvVOF9LE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Una soluzione drastica consiste nel rimuove gli esempi che presentano valori mancanti utilizzando il metodo dropna."
      ]
    },
    {
      "metadata": {
        "id": "Jz3EjQijF9LF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6e1a8057-6868-4b93-eef3-165a6f35e462"
      },
      "cell_type": "code",
      "source": [
        "samples_before = iris_nan.shape[0]\n",
        "iris_drop = iris_nan.dropna()\n",
        "\n",
        "samples_after = iris_drop.shape[0]\n",
        "\n",
        "print(\"Numero di esempi prima: \"+str(samples_before))\n",
        "print(\"Numero di esempi dopo: \"+str(samples_after))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Numero di esempi prima: 150\n",
            "Numero di esempi dopo: 140\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eNfEOg3oF9LI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Se i valori mancanti corrispondono ad un unica feature e questi sono in un numero tale da invalidare l'utilità della feature, allora possiamo semplicemente rimuovere la feature dal nostro DataFrame."
      ]
    },
    {
      "metadata": {
        "id": "IK8ok7QLF9LJ",
        "colab_type": "code",
        "colab": {},
        "outputId": "a5da348f-5b08-4344-a9d9-ad4b8f345574"
      },
      "cell_type": "code",
      "source": [
        "iris_cleaned = iris_nan.dropna(axis=1)\n",
        "iris_cleaned.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['sepal_length', 'sepal_width', 'petal_width', 'class'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "MmmP690zF9LM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Rinunciare a dati preziosi non è mai una buona cosa, quindi questi metodi vanno evitati ad eccezione di casi estremi, ovvero quando la maggior parte dei valori per una feature o per un esempio sono mancanti."
      ]
    },
    {
      "metadata": {
        "id": "Nm4lLH38F9LN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## - Metodo 2: Imputazione dei dati mancanti"
      ]
    },
    {
      "metadata": {
        "id": "t2d32JhUF9LO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "L'imputazione dei dati mancanti consiste nel sostituire i valori con una stima.<br>\n",
        "Il metodo più comune è **l'imputazione con media** (mean imputation) in cui i valori mancanti vengono sostituiti con il valore medio della proprietà, altri metodi sono l'imputazione con la mediana o con valore più frequente (moda)."
      ]
    },
    {
      "metadata": {
        "id": "lqOGc8IGF9LO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Pandas\n",
        "Con Pandas possiamo utilizzare il metodo fillna per sostituire i valori mancanti con le stime."
      ]
    },
    {
      "metadata": {
        "id": "gBz9SNKVF9LQ",
        "colab_type": "code",
        "colab": {},
        "outputId": "ef0b08f9-a29f-4294-c683-6ea117f27328"
      },
      "cell_type": "code",
      "source": [
        "replace_with = iris_nan['petal_length'].mean() # imputazione con media\n",
        "#replace_with = iris_nan['petal_length'].median() # imputazione con mediana\n",
        "#replace_with = iris_nan['petal_length'].mode() # imputazione con moda\n",
        "iris_nan['petal_length'].fillna(replace_with,inplace=True)\n",
        "nan_count = iris_nan['petal_length'].isnull().sum() #verifichiamo che la colonna \"petal_length\" non contenga più valori non validi.\n",
        "print(\"Il dataset ha \"+str(nan_count)+\" valori mancanti\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Il dataset ha 0 valori mancanti\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vuGuZ2iAF9LU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Numpy e Scikit-learn\n",
        "Per eseguire l'imputazione di un array numpy possiamo utilizzare la classe Imputer di scikit-learn, il tipo di imputazione può essere specificata nella strategia (mean, median, most_frequent)"
      ]
    },
    {
      "metadata": {
        "id": "cXzSfVYGGlBn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fb9e9bdd-f685-4b6b-c04c-90c95335fa94"
      },
      "cell_type": "code",
      "source": [
        "nan_count = np.count_nonzero(np.isnan(X))\n",
        "print(\"Il dataset ha \"+str(nan_count)+\" valori mancanti\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Il dataset ha 10 valori mancanti\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "upsXA315F9LW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "a8588f14-3304-4e31-a925-25f60f22f7fd"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import Imputer\n",
        "\n",
        "imp = Imputer(missing_values=\"NaN\", strategy=\"mean\", axis=0) \n",
        "X_imp = imp.fit_transform(X)\n",
        "nan_count = np.count_nonzero(np.isnan(X_imp))\n",
        "print(\"Il dataset ha \"+str(nan_count)+\" valori mancanti\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Il dataset ha 0 valori mancanti\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
            "  warnings.warn(msg, category=DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "0FkZOzmbJCZH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Dalla versione 0.20 di Scikit-learn la classe Imputer è stata deprecata in favore della classe SimpleImputer. L'utilizzo di questa nuova classe è il medesimo, l'unica differenza sta nel fatto che non accetta come valore del parametro *missing_values* una stringa, piuttosto dobbiamo passargli la costante *nan* di Numpy"
      ]
    },
    {
      "metadata": {
        "id": "QcNYyewSHCw1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3b597a75-58cf-46a9-dc99-3442db0af190"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "imp = SimpleImputer(missing_values = np.nan, strategy = 'mean')\n",
        "X_imp = imp.fit_transform(X)\n",
        "\n",
        "nan_count = np.count_nonzero(np.isnan(X_imp))\n",
        "print(\"Il dataset ha \"+str(nan_count)+\" valori mancanti\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Il dataset ha 0 valori mancanti\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}